{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading netcdf4 files (LHM uitvoer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_toolkits.basemap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-959b7bf909c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m  \u001b[0;31m# http://code.google.com/p/netcdf4-python/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddcyclic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshiftgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NAME\n",
    "    NetCDF with Python\n",
    "PURPOSE\n",
    "    To demonstrate how to read and write data with NetCDF files using\n",
    "    a NetCDF file from the NCEP/NCAR Reanalysis.\n",
    "    Plotting using Matplotlib and Basemap is also shown.\n",
    "PROGRAMMER(S)\n",
    "    Chris Slocum\n",
    "REVISION HISTORY\n",
    "    20140320 -- Initial version created and posted online\n",
    "    20140722 -- Added basic error handling to ncdump\n",
    "                Thanks to K.-Michael Aye for highlighting the issue\n",
    "REFERENCES\n",
    "    netcdf4-python -- http://code.google.com/p/netcdf4-python/\n",
    "    NCEP/NCAR Reanalysis -- Kalnay et al. 1996\n",
    "        http://dx.doi.org/10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2\n",
    "'''\n",
    "import datetime as dt  # Python standard library datetime  module\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset  # http://code.google.com/p/netcdf4-python/\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap, addcyclic, shiftgrid\n",
    "\n",
    "\n",
    "def ncdump(nc_fid, verb=True):\n",
    "    '''\n",
    "    ncdump outputs dimensions, variables and their attribute information.\n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_fid : netCDF4.Dataset\n",
    "        A netCDF4 dateset object\n",
    "    verb : Boolean\n",
    "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nc_attrs : list\n",
    "        A Python list of the NetCDF file global attributes\n",
    "    nc_dims : list\n",
    "        A Python list of the NetCDF file dimensions\n",
    "    nc_vars : list\n",
    "        A Python list of the NetCDF file variables\n",
    "    '''\n",
    "    def print_ncattr(key):\n",
    "        \"\"\"\n",
    "        Prints the NetCDF file attributes for a given key\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : unicode\n",
    "            a valid netCDF4.Dataset.variables key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\t\\ttype:\", repr(nc_fid.variables[key].dtype))\n",
    "            for ncattr in nc_fid.variables[key].ncattrs():\n",
    "                print(f'\\t\\t{ncattr}:',\\\n",
    "                      repr(nc_fid.variables[key].getncattr(ncattr)))\n",
    "        except KeyError:\n",
    "            print(f\"\\t\\tWARNING: {key} does not contain variable attributes\")\n",
    "\n",
    "    # NetCDF global attributes\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    if verb:\n",
    "        print(\"NetCDF Global Attributes:\")\n",
    "        for nc_attr in nc_attrs:\n",
    "            print (f'\\t{nc_attr}:', repr(nc_fid.getncattr(nc_attr)))\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    # Dimension shape information.\n",
    "    if verb:\n",
    "        print (\"NetCDF dimension information:\")\n",
    "        for dim in nc_dims:\n",
    "            print (\"\\tName:\", dim) \n",
    "            print (\"\\t\\tsize:\", len(nc_fid.dimensions[dim]))\n",
    "            print_ncattr(dim)\n",
    "    # Variable information.\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    if verb:\n",
    "        print (\"NetCDF variable information:\")\n",
    "        for var in nc_vars:\n",
    "            if var not in nc_dims:\n",
    "                print ('\\tName:', var)\n",
    "                print (\"\\t\\tdimensions:\", nc_fid.variables[var].dimensions)\n",
    "                print (\"\\t\\tsize:\", nc_fid.variables[var].size)\n",
    "                print_ncattr(var)\n",
    "    return nc_attrs, nc_dims, nc_vars\n",
    "\n",
    "nc_f = '/Users/Theo/downloads/ghg_1998-2006_l1.nc'  # Your filename\n",
    "nc_fid = Dataset(nc_f, 'r')  # Dataset is the class behavior to open the file\n",
    "                             # and create an instance of the ncCDF4 class\n",
    "nc_attrs, nc_dims, nc_vars = ncdump(nc_fid)\n",
    "# Extract data from NetCDF file\n",
    "lats = nc_fid.variables['lat'][:]  # extract/copy the data\n",
    "lons = nc_fid.variables['lon'][:]\n",
    "time = nc_fid.variables['time'][:]\n",
    "air = nc_fid.variables['air'][:]  # shape is time, lat, lon as shown above\n",
    "\n",
    "time_idx = 237  # some random day in 2012\n",
    "# Python and the renalaysis are slightly off in time so this fixes that problem\n",
    "offset = dt.timedelta(hours=48)\n",
    "# List of all times in the file as datetime objects\n",
    "dt_time = [dt.date(1, 1, 1) + dt.timedelta(hours=t) - offset\\\n",
    "           for t in time]\n",
    "cur_time = dt_time[time_idx]\n",
    "\n",
    "# Plot of global temperature on our random day\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0., right=1., bottom=0., top=0.9)\n",
    "# Setup the map. See http://matplotlib.org/basemap/users/mapsetup.html\n",
    "# for other projections.\n",
    "m = Basemap(projection='moll', llcrnrlat=-90, urcrnrlat=90,\\\n",
    "            llcrnrlon=0, urcrnrlon=360, resolution='c', lon_0=0)\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "# Make the plot continuous\n",
    "air_cyclic, lons_cyclic = addcyclic(air[time_idx, :, :], lons)\n",
    "# Shift the grid so lons go from -180 to 180 instead of 0 to 360.\n",
    "air_cyclic, lons_cyclic = shiftgrid(180., air_cyclic, lons_cyclic, start=False)\n",
    "# Create 2D lat/lon arrays for Basemap\n",
    "lon2d, lat2d = np.meshgrid(lons_cyclic, lats)\n",
    "# Transforms lat/lon into plotting coordinates for projection\n",
    "x, y = m(lon2d, lat2d)\n",
    "# Plot of air temperature with 11 contour intervals\n",
    "cs = m.contourf(x, y, air_cyclic, 11, cmap=plt.cm.Spectral_r)\n",
    "cbar = plt.colorbar(cs, orientation='horizontal', shrink=0.5)\n",
    "cbar.set_label(\"%s (%s)\" % (nc_fid.variables['air'].var_desc,\\\n",
    "                            nc_fid.variables['air'].units))\n",
    "plt.title(\"%s on %s\" % (nc_fid.variables['air'].var_desc, cur_time))\n",
    "\n",
    "# Writing NetCDF files\n",
    "# For this example, we will create two NetCDF4 files. One with the global air\n",
    "# temperature departure from its value at Darwin, Australia. The other with\n",
    "# the temperature profile for the entire year at Darwin.\n",
    "darwin = {'name': 'Darwin, Australia', 'lat': -12.45, 'lon': 130.83}\n",
    "\n",
    "# Find the nearest latitude and longitude for Darwin\n",
    "lat_idx = np.abs(lats - darwin['lat']).argmin()\n",
    "lon_idx = np.abs(lons - darwin['lon']).argmin()\n",
    "\n",
    "# Simple example: temperature profile for the entire year at Darwin.\n",
    "# Open a new NetCDF file to write the data to. For format, you can choose from\n",
    "# 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "w_nc_fid = Dataset('darwin_2012.nc', 'w', format='NETCDF4')\n",
    "w_nc_fid.description = \"NCEP/NCAR Reanalysis %s from its value at %s. %s\" %\\\n",
    "                      (nc_fid.variables['air'].var_desc.lower(),\\\n",
    "                       darwin['name'], nc_fid.description)\n",
    "# Using our previous dimension info, we can create the new time dimension\n",
    "# Even though we know the size, we are going to set the size to unknown\n",
    "w_nc_fid.createDimension('time', None)\n",
    "w_nc_dim = w_nc_fid.createVariable('time', nc_fid.variables['time'].dtype,\\\n",
    "                                   ('time',))\n",
    "# You can do this step yourself but someone else did the work for us.\n",
    "for ncattr in nc_fid.variables['time'].ncattrs():\n",
    "    w_nc_dim.setncattr(ncattr, nc_fid.variables['time'].getncattr(ncattr))\n",
    "# Assign the dimension data to the new NetCDF file.\n",
    "w_nc_fid.variables['time'][:] = time\n",
    "w_nc_var = w_nc_fid.createVariable('air', 'f8', ('time'))\n",
    "w_nc_var.setncatts({'long_name': u\"mean Daily Air temperature\",\\\n",
    "                    'units': u\"degK\", 'level_desc': u'Surface',\\\n",
    "                    'var_desc': u\"Air temperature\",\\\n",
    "                    'statistic': u'Mean\\nM'})\n",
    "w_nc_fid.variables['air'][:] = air[time_idx, lat_idx, lon_idx]\n",
    "w_nc_fid.close()  # close the new file\n",
    "\n",
    "# A plot of the temperature profile for Darwin in 2012\n",
    "fig = plt.figure()\n",
    "plt.plot(dt_time, air[:, lat_idx, lon_idx], c='r')\n",
    "plt.plot(dt_time[time_idx], air[time_idx, lat_idx, lon_idx], c='b', marker='o')\n",
    "plt.text(dt_time[time_idx], air[time_idx, lat_idx, lon_idx], cur_time,\\\n",
    "         ha='right')\n",
    "fig.autofmt_xdate()\n",
    "plt.ylabel(\"%s (%s)\" % (nc_fid.variables['air'].var_desc,\\\n",
    "                        nc_fid.variables['air'].units))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"%s from\\n%s for %s\" % (nc_fid.variables['air'].var_desc,\\\n",
    "                                  darwin['name'], cur_time.year))\n",
    "\n",
    "# Complex example: global temperature departure from its value at Darwin\n",
    "departure = air[:, :, :] - air[:, lat_idx, lon_idx].reshape((time.shape[0],\\\n",
    "                                                             1, 1))\n",
    "\n",
    "# Open a new NetCDF file to write the data to. For format, you can choose from\n",
    "# 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "w_nc_fid = Dataset('air.departure.sig995.2012.nc', 'w', format='NETCDF4')\n",
    "w_nc_fid.description = \"The departure of the NCEP/NCAR Reanalysis \" +\\\n",
    "                      \"%s from its value at %s. %s\" %\\\n",
    "                      (nc_fid.variables['air'].var_desc.lower(),\\\n",
    "                       darwin['name'], nc_fid.description)\n",
    "# Using our previous dimension information, we can create the new dimensions\n",
    "data = {}\n",
    "for dim in nc_dims:\n",
    "    w_nc_fid.createDimension(dim, nc_fid.variables[dim].size)\n",
    "    data[dim] = w_nc_fid.createVariable(dim, nc_fid.variables[dim].dtype,\\\n",
    "                                        (dim,))\n",
    "    # You can do this step yourself but someone else did the work for us.\n",
    "    for ncattr in nc_fid.variables[dim].ncattrs():\n",
    "        data[dim].setncattr(ncattr, nc_fid.variables[dim].getncattr(ncattr))\n",
    "# Assign the dimension data to the new NetCDF file.\n",
    "w_nc_fid.variables['time'][:] = time\n",
    "w_nc_fid.variables['lat'][:] = lats\n",
    "w_nc_fid.variables['lon'][:] = lons\n",
    "\n",
    "# Ok, time to create our departure variable\n",
    "w_nc_var = w_nc_fid.createVariable('air_dep', 'f8', ('time', 'lat', 'lon'))\n",
    "w_nc_var.setncatts({'long_name': u\"mean Daily Air temperature departure\",\\\n",
    "                    'units': u\"degK\", 'level_desc': u'Surface',\\\n",
    "                    'var_desc': u\"Air temperature departure\",\\\n",
    "                    'statistic': u'Mean\\nM'})\n",
    "w_nc_fid.variables['air_dep'][:] = departure\n",
    "w_nc_fid.close()  # close the new file\n",
    "\n",
    "# Rounded maximum absolute value of the departure used for contouring\n",
    "max_dep = np.round(np.abs(departure[time_idx, :, :]).max()+5., decimals=-1)\n",
    "\n",
    "# Generate a figure of the departure for a single day\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0., right=1., bottom=0., top=0.9)\n",
    "m = Basemap(projection='moll', llcrnrlat=-90, urcrnrlat=90,\\\n",
    "            llcrnrlon=0, urcrnrlon=360, resolution='c', lon_0=0)\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary()\n",
    "dep_cyclic, lons_cyclic = addcyclic(departure[time_idx, :, :], lons)\n",
    "dep_cyclic, lons_cyclic = shiftgrid(180., dep_cyclic, lons_cyclic, start=False)\n",
    "lon2d, lat2d = np.meshgrid(lons_cyclic, lats)\n",
    "x, y = m(lon2d, lat2d)\n",
    "levels = np.linspace(-max_dep, max_dep, 11)\n",
    "cs = m.contourf(x, y, dep_cyclic, levels=levels, cmap=plt.cm.bwr)\n",
    "x, y = m(darwin['lon'], darwin['lat'])\n",
    "plt.plot(x, y, c='c', marker='o')\n",
    "plt.text(x, y, 'Darwin,\\nAustralia', color='r', weight='semibold')\n",
    "cbar = plt.colorbar(cs, orientation='horizontal', shrink=0.5)\n",
    "cbar.set_label(\"%s departure (%s)\" % (nc_fid.variables['air'].var_desc,\\\n",
    "                            nc_fid.variables['air'].units))\n",
    "plt.title(\"Departure of Global %s from\\n%s for %s\" %\\\n",
    "          (nc_fid.variables['air'].var_desc, darwin['name'], cur_time))\n",
    "plt.show()\n",
    "\n",
    "# Close original NetCDF file.\n",
    "nc_fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribs = lambda obj: [o for o in dir(obj) if not o.startswith('_') and not callable(exec(str(obj) '.' + o)]\n",
    "methods = lambda obj: [o for o in dir(obj) if not o.startswith('_') and callable(obj.o)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'netCDF4._netCDF4.Dataset' has no attribute 'o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d0172dca5194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#methods(Dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mattribs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-c5c09e269253>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c5c09e269253>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattribs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'netCDF4._netCDF4.Dataset' has no attribute 'o'"
     ]
    }
   ],
   "source": [
    "#methods(Dataset)\n",
    "attribs(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'get_variables_by_attributes' of 'netCDF4._netCDF4.Dataset' object needs an argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6c9d8efd8ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables_by_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Z'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'get_variables_by_attributes' of 'netCDF4._netCDF4.Dataset' object needs an argument"
     ]
    }
   ],
   "source": [
    "Dataset.get_variables_by_attributes(axis=lambda v: v in ['X', 'Y', 'Z', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orthogonal_indexing__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_close',\n",
       " '_enddef',\n",
       " '_grpid',\n",
       " '_isopen',\n",
       " '_redef',\n",
       " 'close',\n",
       " 'cmptypes',\n",
       " 'createCompoundType',\n",
       " 'createDimension',\n",
       " 'createEnumType',\n",
       " 'createGroup',\n",
       " 'createVLType',\n",
       " 'createVariable',\n",
       " 'data_model',\n",
       " 'delncattr',\n",
       " 'dimensions',\n",
       " 'disk_format',\n",
       " 'enumtypes',\n",
       " 'file_format',\n",
       " 'filepath',\n",
       " 'get_variables_by_attributes',\n",
       " 'getncattr',\n",
       " 'groups',\n",
       " 'isopen',\n",
       " 'keepweakref',\n",
       " 'ncattrs',\n",
       " 'parent',\n",
       " 'path',\n",
       " 'renameAttribute',\n",
       " 'renameDimension',\n",
       " 'renameGroup',\n",
       " 'renameVariable',\n",
       " 'set_always_mask',\n",
       " 'set_auto_chartostring',\n",
       " 'set_auto_mask',\n",
       " 'set_auto_maskandscale',\n",
       " 'set_auto_scale',\n",
       " 'set_fill_off',\n",
       " 'set_fill_on',\n",
       " 'setncattr',\n",
       " 'setncattr_string',\n",
       " 'setncatts',\n",
       " 'sync',\n",
       " 'variables',\n",
       " 'vltypes']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#callable(Dataset.getncattr)\n",
    "[o for o in dir(Dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
